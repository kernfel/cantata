{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cantata\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from cantata.plotting import output as cp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (14,5)\n",
    "\n",
    "batch_size = 1\n",
    "dt = 1e-3\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  n_channels: 1\n",
      "  populations:\n",
      "    Thal:\n",
      "      n: 2\n",
      "      channel: 0\n",
      "      targets:\n",
      "        L1.Exc:\n",
      "          spatial: true\n",
      "          density: 0.5\n",
      "          delay: 0.001\n",
      "          sigma: 0.5\n",
      "          STDP_frac: 0.0\n",
      "          A_p: 0.0\n",
      "          A_d: 0.0\n",
      "          wmax: 1.0\n",
      "        L1.Inh:\n",
      "          spatial: true\n",
      "          density: 0.5\n",
      "          delay: 0.001\n",
      "          sigma: 0.5\n",
      "          STDP_frac: 0.0\n",
      "          A_p: 0.0\n",
      "          A_d: 0.0\n",
      "          wmax: 1.0\n",
      "areas:\n",
      "  L1:\n",
      "    populations:\n",
      "      Exc:\n",
      "        sign: 1\n",
      "        n: 200\n",
      "        p: -0.1\n",
      "        noise_N: 2000\n",
      "        noise_rate: 8.0\n",
      "        noise_weight: 0.002\n",
      "        th_ampl: 0.05\n",
      "        targets:\n",
      "          Exc:\n",
      "            spatial: true\n",
      "            density: 0.5\n",
      "            delay: 0.001\n",
      "            STDP_frac: 1.0\n",
      "            A_p: 1.5\n",
      "            A_d: 0.5\n",
      "            sigma: 0.5\n",
      "            wmax: 1.0\n",
      "          Inh:\n",
      "            spatial: true\n",
      "            density: 0.5\n",
      "            delay: 0.001\n",
      "            sigma: 0.5\n",
      "            STDP_frac: 0.0\n",
      "            A_p: 0.0\n",
      "            A_d: 0.0\n",
      "            wmax: 1.0\n",
      "        tau_mem: 0.02\n",
      "        tau_mem_gamma: 3\n",
      "        tau_ref: 0.005\n",
      "        tau_r: 0.1\n",
      "        th_tau: 1.0\n",
      "      Inh:\n",
      "        sign: -1\n",
      "        n: 56\n",
      "        p: 0.0\n",
      "        noise_N: 1850\n",
      "        noise_rate: 8.0\n",
      "        noise_weight: 0.002\n",
      "        targets:\n",
      "          Exc:\n",
      "            spatial: true\n",
      "            density: 0.5\n",
      "            delay: 0.001\n",
      "            sigma: 0.5\n",
      "            STDP_frac: 0.0\n",
      "            A_p: 0.0\n",
      "            A_d: 0.0\n",
      "            wmax: 1.0\n",
      "          Inh:\n",
      "            spatial: true\n",
      "            density: 0.5\n",
      "            delay: 0.001\n",
      "            sigma: 0.5\n",
      "            STDP_frac: 0.0\n",
      "            A_p: 0.0\n",
      "            A_d: 0.0\n",
      "            wmax: 1.0\n",
      "        tau_mem: 0.02\n",
      "        tau_mem_gamma: 3\n",
      "        tau_ref: 0.005\n",
      "        tau_r: 0.1\n",
      "        th_ampl: 0.0\n",
      "        th_tau: 1.0\n",
      "    tau_x: 0.012\n",
      "    tau_p: 0.03\n",
      "    tau_d: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf = cantata.config.read('/home/felix/projects/cantata/cantata/configs/1tier.yaml')\n",
    "conf.pop('_prototypes')\n",
    "print(conf.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "second = int(1/dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = int(10 * second)\n",
    "rate_off, rate_on = 0, 0 # Hz\n",
    "t_off, t_on = .15*second, .15*second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(n_steps, periods, rates, device = torch.device('cpu'), reshape = True):\n",
    "    seq = torch.arange(n_steps, device=device)\n",
    "    pattern = torch.zeros(n_steps, device=device)\n",
    "    stop, total = 0, int(sum(periods))\n",
    "    for rate, period in zip(rates, periods):\n",
    "        pattern = torch.where(\n",
    "            seq % total > stop,\n",
    "            torch.tensor([rate],device=device,dtype=torch.float),\n",
    "            pattern\n",
    "        )\n",
    "        stop += int(period)\n",
    "    return pattern.reshape(-1,1,1).expand(-1, batch_size, -1) if reshape else pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = get_inputs(n_steps, (t_off,t_on), (rate_off,rate_on), device, reshape=False)\n",
    "# plt.plot(inputs.cpu())\n",
    "\n",
    "# inputs = inputs.reshape(-1,1,1).expand(-1, batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = cantata.Conductor(conf, batch_size, dt, STDP=cantata.elements.Abbott).to(device)\n",
    "# with torch.no_grad():\n",
    "#     X = m(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STDP_mask(area, name_pre, name_post):\n",
    "    e,o = area.N, area.N\n",
    "    pre = area.p_idx[area.p_names.index(name_pre)]\n",
    "    post = area.p_idx[area.p_names.index(name_post)]\n",
    "    synapse = area.synapses_int\n",
    "    \n",
    "    projection = torch.zeros(e,o, dtype=torch.bool) # (e,o)\n",
    "    projection[np.ix_(pre, post)] = True\n",
    "    \n",
    "    active = synapse.signs != 0 # (e,o)\n",
    "    \n",
    "    plastic = (synapse.longterm.A_p != 0) * (synapse.longterm.A_d != 0) # (e,o)\n",
    "    \n",
    "    mask = active * plastic * projection.to(active) # (e,o)\n",
    "    return mask\n",
    "    \n",
    "#     mask_cpu = mask.cpu()\n",
    "#     e,o = synapse.signs.shape\n",
    "#     pre = torch.arange(e).unsqueeze(1).expand(e,o)[mask_cpu]\n",
    "#     post = torch.arange(o).expand(e,o)[mask_cpu]\n",
    "#     return mask, (pre, post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_unstimulated(model, early = (10,20), late = (50,60)):\n",
    "    def get_empty(secs):\n",
    "        return get_inputs(int(secs * second), (0,), (0,), device)\n",
    "#     def record_W(mask):\n",
    "#         def inner(m, *args):\n",
    "#             W.append(m.W[:, mask])\n",
    "#         return inner\n",
    "    STDP = model.areas[0].synapses_int.longterm\n",
    "    mask = get_STDP_mask(model.areas[0], 'Exc', 'Exc')\n",
    "    \n",
    "    # Settle without observation until early begins:\n",
    "    if early[0] > 0:\n",
    "        model(get_empty(early[0]))\n",
    "    \n",
    "    # Observe spikes, STDP in early window:\n",
    "#     observer = STDP.register_forward_hook(record_W(mask))\n",
    "#     W = []\n",
    "    Wpre = STDP.W[:, mask]\n",
    "    X = model(get_empty(early[1] - early[0]))\n",
    "    Wpost = STDP.W[:, mask]\n",
    "#     observer.remove()\n",
    "    w0 = get_stdp_measures(torch.stack((Wpre, Wpost)) / conf.areas.L1.populations.Exc.targets.Exc.wmax)\n",
    "    r0 = get_rate_measures(X[1], model.areas[0])\n",
    "    \n",
    "    # Run through to late window:\n",
    "    model(get_empty(late[0] - early[1]))\n",
    "    \n",
    "    # Observe spikes, STDP in late window:\n",
    "#     observer = STDP.register_forward_hook(record_W(mask))\n",
    "#     W = []\n",
    "    Wpre = STDP.W[:, mask]\n",
    "    X = model(get_empty(late[1] - late[0]))\n",
    "    Wpost = STDP.W[:, mask]\n",
    "#     observer.remove()\n",
    "    w1 = get_stdp_measures(torch.stack((Wpre, Wpost)) / conf.areas.L1.populations.Exc.targets.Exc.wmax, t=-1)\n",
    "    r1 = get_rate_measures(X[1], model.areas[0])\n",
    "    \n",
    "    return r0, w0, r1, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_measures(X, area, quantiles = [0, .1, .25, .5, .75, .9, 1]):\n",
    "    # X: (t,b,N) in area\n",
    "    rates = X.sum(dim=(0,1)) / (X.shape[0] * X.shape[1] * dt) # Hz, (N)\n",
    "    ret = torch.zeros(len(area.p_idx), len(quantiles)+2)\n",
    "    for i, idx in enumerate(area.p_idx):\n",
    "        ret[i,2:] = torch.quantile(rates[idx], torch.tensor(quantiles).to(rates))\n",
    "        ret[i,1], ret[i,0] = torch.std_mean(rates[idx])\n",
    "    return ret.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stdp_measures(W, t = 0, quantiles = [0, .1, .25, .5, .75, .9, 1], tol = 1e-4):\n",
    "    # W: (t,b,masked)\n",
    "    q = torch.quantile(W[t], torch.tensor(quantiles).to(W)).cpu()\n",
    "    std, mean = torch.std_mean(W[t])\n",
    "    \n",
    "    # Cosine similarity between the weight vectors in different batches\n",
    "    # : Distance between batches\n",
    "    batch_size = W.shape[1]\n",
    "    i,j = torch.triu_indices(batch_size, batch_size, 1)\n",
    "    cs = torch.nn.functional.cosine_similarity(W[t], W[t].unsqueeze(1), dim=-1)\n",
    "    batch_std, batch_mean = torch.std_mean(cs[i,j])\n",
    "    \n",
    "    # Cosine similarity between weight vectors at start & end of period; mean & std:\n",
    "    # : Distance between time points\n",
    "    cs = torch.nn.functional.cosine_similarity(W[0], W[-1], dim=1)\n",
    "    time_std, time_mean = torch.std_mean(cs)\n",
    "    \n",
    "    # Proportion of saturated weights at higher/lower weight bound\n",
    "    sat_norm = W.shape[1] * W.shape[2]\n",
    "    sat_high, sat_low = torch.sum(W[t] > 1-tol)/sat_norm, torch.sum(W[t] < tol)/sat_norm\n",
    "    \n",
    "    ret = torch.tensor([batch_mean, batch_std, time_mean, time_std, mean, std, sat_high, sat_low])\n",
    "    return torch.cat((ret, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimulated_measures(X, area, periods, onset = 20, quantiles = [0, .1, .25, .5, .75, .9, 1], sig=.05):\n",
    "    # X: (t,b,N) in area\n",
    "    stop, total = 0, int(sum(periods))\n",
    "    nperiods, nreps = len(periods), X.shape[0] // total\n",
    "    batch_size, N = X.shape[1], X.shape[2]\n",
    "    assert total*nreps == X.shape[0], 'Periods must neatly tile the input.'\n",
    "    \n",
    "    r_pulse = torch.empty(nperiods, nreps, batch_size, N)\n",
    "    r_onset = torch.empty(nperiods, nreps, batch_size, N)\n",
    "    for i,p in enumerate(periods):\n",
    "        p = int(p)\n",
    "        idx = torch.arange(stop, stop+p).expand(nreps,-1) + (torch.arange(nreps)*total)[:,None]\n",
    "        S = X[idx,:,:] # (nreps, p, b, N)\n",
    "        r_pulse[i] = S.sum(dim=1).cpu() / (p * dt) # Hz, (nreps, b, N)\n",
    "        r_onset[i] = S[:,:onset].sum(dim=1).cpu() / (onset * dt) # Hz\n",
    "        stop += p\n",
    "    \n",
    "    ret = torch.empty(len(area.p_idx), nperiods, len(quantiles)+4)\n",
    "    for i,idx in enumerate(area.p_idx):\n",
    "        rx_pulse = r_pulse[:,:,:,idx] # (nperiods, nreps, b, Nx)\n",
    "        rx_onset = r_onset[:,:,:,idx]\n",
    "\n",
    "        # Firing rates during each stimulus (full pulse duration)\n",
    "        # Note, batch instances are treated as separate networks, since they may have self-organised differently\n",
    "        r = rx_pulse.sum(dim=1) / nreps # Hz, (nperiods, b, Nx)\n",
    "        std_pulse, mean_pulse = torch.std_mean(r, dim=(1,2)) # (nperiods)\n",
    "        q_pulse = np.quantile(r.numpy(), np.array(quantiles), axis=(1,2)) # (|q|, nperiods)\n",
    "        q_pulse = torch.tensor(q_pulse, dtype=torch.float)\n",
    "        \n",
    "        # Finding pulse level sensitive units\n",
    "        # 2-tailed independent test; assumes that on and off are independent, even though they follow each other\n",
    "        # Value reflects the fraction of units that significantly increase their firing for a given stimulus.\n",
    "        level_sensitive = torch.empty(nperiods) # (nperiods)\n",
    "        for j in range(nperiods):\n",
    "            off = [k for k in range(nperiods) if k != j]\n",
    "            if nperiods > 2:\n",
    "                raise NotImplemented\n",
    "            else:\n",
    "                rx_off = rx_pulse[off]\n",
    "            _, p = scipy.stats.ttest_ind(\n",
    "                rx_pulse[j].numpy(), rx_off.numpy(), axis=0, alternative='greater') # (b, Nx)\n",
    "            level_sensitive[j] = np.sum(p<sig) / (batch_size*N) # scalar\n",
    "\n",
    "        # Finding onset-selective units\n",
    "        # 2-tailed paired test, since onset and rest-of-pulse are tightly linked\n",
    "        _, p = scipy.stats.ttest_rel(rx_onset, rx_pulse, axis=1) # (nperiods, b, Nx)\n",
    "        onset_sensitive = np.sum(p<sig, axis=(1,2)) / (batch_size*N) # (nperiods)\n",
    "        onset_sensitive = torch.tensor(onset_sensitive, dtype=torch.float)\n",
    "        \n",
    "        ret[i] = torch.cat((\n",
    "            mean_pulse[:,None],\n",
    "            std_pulse[:,None],\n",
    "            q_pulse.T,\n",
    "            level_sensitive[:,None],\n",
    "            onset_sensitive[:,None]\n",
    "        ), dim=1)\n",
    "    return ret # (nareas, nperiods, |q|+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_stimulated(model, periods, rates, onset = 20, settle = 5, early = (10,15), late = (55,60)):\n",
    "    '''Expects period, onset in ticks; settle, early, late in seconds.'''\n",
    "    assert second % sum(periods) == 0, 'Periods must tile neatly into 1-second segments.'\n",
    "    for p in periods:\n",
    "        assert p > onset, 'Periods must be longer than the onset'\n",
    "    def record_W(mask):\n",
    "        def inner(m, *args):\n",
    "            W.append(m.W[:, mask])\n",
    "        return inner\n",
    "    STDP = model.areas[0].synapses_int.longterm\n",
    "    mask = get_STDP_mask(model.areas[0], 'Exc', 'Exc')\n",
    "    \n",
    "    # Settle without observation and without stimulation:\n",
    "    if settle > 0:\n",
    "        model(get_inputs(int(settle * second), (0,), (0,), device))\n",
    "    \n",
    "    inputs = get_inputs(int(late[1]*second), periods, rates)\n",
    "    \n",
    "    # Run without observation until early begins:\n",
    "    t = 0\n",
    "    if early[0] > 0:\n",
    "        t = int(early[0] * second)\n",
    "        model(inputs[:t].to(device))\n",
    "    \n",
    "    # Observe spikes, STDP in early window:\n",
    "    t0, t = t, int(early[1] * second)\n",
    "    Wpre = STDP.W[:, mask]\n",
    "    X = model(inputs[t0:t].to(device))\n",
    "    Wpost = STDP.W[:, mask]\n",
    "    w0 = get_stdp_measures(torch.stack((Wpre, Wpost)) / conf.areas.L1.populations.Exc.targets.Exc.wmax)\n",
    "    r0 = get_rate_measures(X[1], model.areas[0])\n",
    "    s0 = get_stimulated_measures(X[1], model.areas[0], periods)\n",
    "    \n",
    "    # Run through to late window:\n",
    "    t0, t = t, int(late[0] * second)\n",
    "    model(inputs[t0:t].to(device))\n",
    "    \n",
    "    # Observe spikes, STDP in late window:\n",
    "    t0, t = t, int(late[1] * second)\n",
    "    Wpre = STDP.W[:, mask]\n",
    "    X = model(inputs[t0:t].to(device))\n",
    "    Wpost = STDP.W[:, mask]\n",
    "    w1 = get_stdp_measures(torch.stack((Wpre, Wpost)) / conf.areas.L1.populations.Exc.targets.Exc.wmax, t=-1)\n",
    "    r1 = get_rate_measures(X[1], model.areas[0])\n",
    "    s1 = get_stimulated_measures(X[1], model.areas[0], periods)\n",
    "    \n",
    "    return r0, w0, s0, r1, w1, s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = (int(50e-3/dt), int(50e-3/dt)) # ticks\n",
    "rates = (0, 50) # Hz\n",
    "\n",
    "settle, early, late = 5, (10,15), (55,60) # seconds\n",
    "\n",
    "assert second % sum(periods) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/projects/cantata/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3621: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/felix/projects/cantata/venv/lib/python3.8/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "m = cantata.Conductor(conf, batch_size, dt, STDP=cantata.elements.Abbott).to(device)\n",
    "with torch.no_grad():\n",
    "    r0_u, w0_u, r1_u, w1_u = quantify_unstimulated(m, early=early, late=late)\n",
    "    m.reset()\n",
    "    r0_s, w0_s, s0, r1_s, w1_s, s1 = quantify_stimulated(m, periods, rates, settle=settle, early=early, late=late)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12.8770,  3.0011,  0.0000,  9.8681, 12.2375, 13.4250, 14.4734, 15.6700,\n",
       "          19.2125],\n",
       "         [12.1128,  5.6502,  0.4813,  4.7375,  9.0250, 13.0125, 14.4703, 16.5688,\n",
       "          26.6562]]),\n",
       " tensor([0.9887, 0.0036, 0.9977, 0.0016, 0.9261, 0.1797, 0.5062, 0.0115, 0.0000,\n",
       "         0.9062, 0.9314, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       " tensor([[13.4670,  2.9992,  0.0000, 10.3294, 12.7453, 14.0000, 15.1156, 16.3100,\n",
       "          19.7000],\n",
       "         [12.6037,  5.8171,  0.2875,  4.8250,  9.3938, 13.5188, 15.1875, 17.3469,\n",
       "          27.1562]]),\n",
       " tensor([9.8792e-01, 3.6498e-03, 9.9875e-01, 3.5875e-04, 9.3460e-01, 1.7337e-01,\n",
       "         5.1857e-01, 1.7836e-02, 0.0000e+00, 9.0808e-01, 9.3410e-01, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r0_u, w0_u, r1_u, w1_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[13.7054,  3.1407,  0.0000, 10.6238, 13.0016, 14.3125, 15.4297, 16.5637,\n",
       "          19.9500],\n",
       "         [12.8563,  5.9270,  0.5000,  5.0781,  9.4453, 13.7531, 15.5891, 17.5531,\n",
       "          27.5000]]),\n",
       " tensor([9.8923e-01, 3.3350e-03, 9.9833e-01, 9.8585e-04, 9.2852e-01, 1.7353e-01,\n",
       "         4.7546e-01, 1.1571e-02, 0.0000e+00, 9.0411e-01, 9.3253e-01, 9.7510e-01,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       " tensor([[13.5378,  2.9360,  0.0000, 10.5050, 12.8375, 14.0875, 15.1719, 16.3188,\n",
       "          19.7812],\n",
       "         [12.7041,  5.8457,  0.4813,  4.8813,  9.3891, 13.5719, 15.2328, 17.5031,\n",
       "          27.2437]]),\n",
       " tensor([9.8861e-01, 3.4260e-03, 9.9866e-01, 7.9792e-04, 9.3570e-01, 1.6746e-01,\n",
       "         5.1252e-01, 1.5468e-02, 0.0000e+00, 9.1033e-01, 9.3234e-01, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 1.0000e+00]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r0_s, w0_s, r1_s, w1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.3376e+01, 4.0665e+00, 0.0000e+00, 9.6000e+00, 1.1600e+01,\n",
       "           1.3600e+01, 1.5600e+01, 1.7600e+01, 2.5200e+01, 0.0000e+00,\n",
       "           1.7944e-02],\n",
       "          [1.4035e+01, 3.9213e+00, 0.0000e+00, 1.0400e+01, 1.2400e+01,\n",
       "           1.4400e+01, 1.6400e+01, 1.8000e+01, 2.4000e+01, 0.0000e+00,\n",
       "           6.5918e-03]],\n",
       " \n",
       "         [[1.2567e+01, 6.3235e+00, 0.0000e+00, 4.0000e+00, 8.8000e+00,\n",
       "           1.2800e+01, 1.6000e+01, 2.0800e+01, 3.3600e+01, 0.0000e+00,\n",
       "           5.1270e-03],\n",
       "          [1.3146e+01, 6.2060e+00, 0.0000e+00, 4.8000e+00, 9.6000e+00,\n",
       "           1.3400e+01, 1.6400e+01, 2.0760e+01, 3.3600e+01, 0.0000e+00,\n",
       "           2.5635e-03]]]),\n",
       " tensor([[[1.3261e+01, 3.7881e+00, 0.0000e+00, 9.6000e+00, 1.1600e+01,\n",
       "           1.3600e+01, 1.5600e+01, 1.7200e+01, 2.4400e+01, 0.0000e+00,\n",
       "           2.4780e-02],\n",
       "          [1.3815e+01, 4.1342e+00, 0.0000e+00, 1.0000e+01, 1.2000e+01,\n",
       "           1.4000e+01, 1.6000e+01, 1.8400e+01, 2.6800e+01, 0.0000e+00,\n",
       "           1.5869e-02]],\n",
       " \n",
       "         [[1.2448e+01, 6.2139e+00, 0.0000e+00, 3.6400e+00, 8.8000e+00,\n",
       "           1.2400e+01, 1.5600e+01, 2.0400e+01, 3.1600e+01, 0.0000e+00,\n",
       "           4.2725e-03],\n",
       "          [1.2961e+01, 6.3195e+00, 0.0000e+00, 4.8000e+00, 9.2000e+00,\n",
       "           1.2800e+01, 1.6000e+01, 2.1600e+01, 3.4800e+01, 0.0000e+00,\n",
       "           5.1270e-03]]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0, s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cantata",
   "language": "python",
   "name": "cantata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
